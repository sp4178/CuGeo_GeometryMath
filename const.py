# TOKEN
ENCODER_MAX_SEQ_LENGTH = 200
TEXT_EMBEDDING_TOKEN = "<text_embedding>"
IMAGE_START_TOKEN = "<image_start>"
IMAGE_PATCH_TOKEN = "<image_patch>"
IMAGE_END_TOKEN = "<image_end>"

# for calculate Loss
IGNORE_INDEX = -100

# for calculate image patch length
PATCH_SIZE = 14 # for "openai/clip-vit-large-patch14"